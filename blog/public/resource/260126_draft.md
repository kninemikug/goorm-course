[Pandas] 데이터프레임 완전 정복: 사칙연산부터 Groupby 심화까지
데이터 분석을 하다 보면 데이터를 단순히 불러오는 걸 넘어, 서로 연산하거나 그룹별로 묶어서 통계를 내야 할 때가 반드시 온다. 오늘은 Pandas DataFrame의 핵심인 객체 간 연산, 이동 계산(Rolling), 그리고 강력한 그룹화(Groupby) 기능을 정리해본다.

1. 객체 간 연산: 그냥 +, - 기호 쓰면 안 되나?
결론부터 말하면 된다. 하지만 Pandas가 제공하는 메서드(add, sub, mul, div)를 쓰면 **결측치(NaN)**를 훨씬 유연하게 처리할 수 있다.

1-1. 기본 연산과 Broadcasting
데이터프레임에 스칼라(숫자 하나)를 더하면 모든 원소에 값이 더해진다(Broadcasting).

Python

import pandas as pd
import numpy as np

data = [[1,10,100],[2,20,200],[3,30,300]]
col = ['col1','col2','col3']
row = ['row1','row2','row3']
df = pd.DataFrame(data=data, index=row, columns=col)

print(df)
결과:

Plaintext

      col1  col2  col3
row1     1    10   100
row2     2    20   200
row3     3    30   300
여기에 1을 더해보자. add 메서드와 + 연산자의 결과는 같다.

Python

result1 = df.add(1)
result2 = df + 1
print(result1)
결과:

Plaintext

      col1  col2  col3
row1     2    11   101
row2     3    21   201
row3     4    31   301
1-2. fill_value의 마법 (사칙연산 전체 적용)
모양(Shape)이 다른 두 데이터프레임을 연산할 때 진가가 드러난다. 짝이 안 맞는 부분은 원래 NaN이 되지만, 메서드를 쓰면 fill_value로 채우고 계산한다. 이건 덧셈(add)뿐만 아니라 뺄셈(sub), 곱셈(mul), 나눗셈(div) 모두 동일하게 적용된다.

Python

data2  = [[3],[4],[5]]
df2 = pd.DataFrame(data=data2, index=['row1','row2','row3'], columns=['col1'])

# 그냥 더하기: 짝이 없는 col2, col3는 NaN이 됨
result2 = df + df2
print(result2)

# 메서드 활용: 없는 값은 0으로 채우고 더함
result3 = df.add(df2, fill_value=0)
print(result3)
결과 (result2 vs result3):

Plaintext

# result2 (단순 연산)
      col1  col2  col3
row1     4   NaN   NaN
row2     6   NaN   NaN
row3     8   NaN   NaN

# result3 (fill_value=0 적용)
      col1  col2   col3
row1     4  10.0  100.0
row2     6  20.0  200.0
row3     8  30.0  300.0
2. 데이터 흐름 읽기: diff와 pct_change
시계열 데이터나 순서가 중요한 데이터에서 '이전 대비 얼마나 변했나'를 볼 때 쓴다.

2-1. 이산 차이 (diff)
특정 시점과 이전 시점의 **절대적인 차이(뺄셈)**를 구한다.

Python

# 예제 데이터 생성
a = [1,2,3,4,5,6,7,8]
b = [1,2,4,8,16,32,64,128]
c = [8,7,6,5,4,3,2,1]
df = pd.DataFrame({"col1":a, "col2":b, "col3":c})

# axis=0 (행 간 차이), 바로 직전 값과 비교
print(df.diff(axis=0))
결과:

Plaintext

   col1  col2  col3
0   NaN   NaN   NaN
1   1.0   1.0  -1.0
2   1.0   2.0  -1.0
... (생략)
7   1.0  64.0  -1.0
Tip: periods=3처럼 옵션을 주면 3칸 전 데이터와 비교한다.

2-2. 백분율 변화 (pct_change)
주식 수익률 구할 때 딱이다. 이전 값 대비 몇 퍼센트 변했는지 보여준다.

Python

print(df.pct_change(limit=1)) 
결과:

Plaintext

   col1  col2  col3
0   NaN   NaN   NaN
1  0.00   1.0   0.0
2  3.00   1.0   NaN ...
3. 누적과 이동: expanding & rolling
데이터의 추세를 보거나 노이즈를 줄일 때 필수다.

expanding(): 시점이 지날수록 데이터가 누적된다. (누적 합, 누적 평균 등)

rolling(): 창문(Window)을 밀면서 계산한다. (이동 평균)

3-1. Window 이동 계산 (rolling)
가장 많이 쓰는 기능이다. window 사이즈만큼 묶어서 계산한다.

Python

# 30분 단위의 시계열 데이터 생성
period = pd.period_range(start='2022-01-13 00:00:00', end='2022-01-13 02:30:00', freq='30min')
df = pd.DataFrame({'col1':[1,2,3,4,5,6], 'col2':period}, index=['row1','row2','row3','row4','row5','row6'])

# 최근 3개 데이터의 합계 (window=3)
print(df['col1'].rolling(window=3).sum())
결과:

Plaintext

row1     NaN
row2     NaN
row3     6.0  # 1+2+3
row4     9.0  # 2+3+4
row5    12.0
row6    15.0
Name: col1, dtype: float64
Tip: win_type='gaussian' 같은 옵션을 주면 가중치를 다르게 줘서 스무딩(Smoothing) 효과를 줄 수도 있다.

4. 끝판왕: groupby 심화
데이터 분석의 꽃이다. Split(나누고) -> Apply(적용하고) -> Combine(합친다).

4-1. 기본 집계 (agg)
여러 통계량을 한 번에 뽑을 때 유용하다.

Python

# 예제 데이터 (랜덤 정수)
idx=['A','A','B','B','B','C','C','C','D','D','D','D','E','E','E']
data = np.random.randint(0,9,(15,3))
df = pd.DataFrame(data=data, index=idx, columns=['col1','col2','col3']).reset_index()

# 그룹별 개수, 합계, 평균 한방에 구하기
print(df.groupby('index').agg(['count','sum','mean']))
결과 (일부):

Plaintext

       col1                col2            
      count sum      mean count sum      mean
index                                        
A         2   9  4.500000     2  11  5.500000
B         3   8  2.666667     3  20  6.666667
...
4-2. 내 맘대로 함수 적용 (apply)
단순 합계/평균 말고, "그룹별로 상위 N개만 뽑고 싶다" 같은 로직이 필요할 때 쓴다.

Python

# 상위 n개를 뽑는 커스텀 함수
def top(df, n=2, col='col1'):
    return df.sort_values(by=col)[-n:]

# 그룹별 적용 (include_groups=False는 최신 판다스 권장 사항)
print(df.groupby('index').apply(top, include_groups=False))
결과:
각 그룹(A, B, C...)에서 col1 기준 값이 큰 상위 2개 행만 추출된다.

4-3. 범주형 데이터와 observed
범주형(Categorical) 데이터로 만들었을 때, 데이터가 없는 카테고리를 결과에 포함할지 말지 결정한다.

Python

df_cat = pd.Categorical(df['index'], categories=['A','B','C','D','E','F'])

# observed=True: 데이터가 있는 그룹만 표시 (F는 안 나옴)
print(df['col1'].groupby(df_cat, observed=True).count())
4-4. 결측치(NaN)도 그룹으로?
기본적으로 groupby는 NaN을 무시한다. 하지만 dropna=False를 쓰면 NaN도 하나의 그룹으로 쳐준다.

Python

# 인위적으로 NaN 생성
df.loc[6,'index'] = np.nan

# NaN 포함해서 그룹핑
print(df.groupby('index', dropna=False).sum())
결과:

Plaintext

       col1  col2  col3
index                  
A         9    11     7
...
NaN       2     3     1  <-- 결측치도 그룹으로 집계됨