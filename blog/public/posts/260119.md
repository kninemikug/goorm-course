# [논문 리뷰] A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks (Sahoo et al., 2024)

## 1. 들어가며

이 글에서 다룰 논문은 **"A Survey of Prompt Engineering Methods in Large Language Models for Different NLP Tasks (Sahoo et al., 2024)"** 이다.

이 논문은 2022년에서 2024년 사이에 쏟아져 나온 다수의 프롬프트 엔지니어링 연구를 집약하여, **NLP 태스크별로 가장 적합한 프롬프트 엔지니어링 방식(SoTA)** 이 무엇인지 규명하는 것을 목표로 한다.

기존 연구들은 저마다의 기준으로 태스크를 정의하고 성능을 평가했기에 직접적인 비교가 어려웠다. 저자들은 이를 해결하기 위해 NLP 태스크를 **29가지로 표준화** 하여 정의하고, 각 데이터셋에서 어떤 프롬프팅 전략이 최고의 성능을 냈는지 분석했다.

논문에서 도출한 주요 태스크와 그에 따른 최적화된 프롬프팅 기법, 그리고 각 기법에 대한 상세한 설명은 다음과 같다.

---

## 2. 태스크별 최적의 프롬프팅 전략

### ① 추론(Reasoning) 관련 태스크
LLM이 가장 어려워하는 복합적인 사고력이 필요한 분야다. 단순히 텍스트를 생성하기보다 문제를 구조적으로 분해하거나 코드를 활용하는 기법이 주효하다.

| 태스크 (Task) | 추천 기법 (SoTA) | 특징 및 이유 |
| :--- | :--- | :--- |
| **수학 문제 해결** | **PoT** / **Analogical** | • **PoT**: 언어로 풀지 않고 파이썬 코드를 생성해 계산.<br>• **Analogical**: 유사한 예시를 스스로 생성해 유추. |
| **논리 추론** | **CoC** | 코딩 로직을 일반 논리 문제에 적용하여 구조 파악 능력 극대화. |
| **상식 추론** | **DecomP** / **Active-Prompt** | • **DecomP**: 문제를 잘게 쪼개서 해결.<br>• **Active-Prompt**: 불확실한 질문에 힌트 제공. |
| **인과 관계 추론** | **LoT** | 다양한 사고 패턴을 도서관처럼 저장해두고 활용. |
| **사회적 추론** | **CoT** | 사회적 맥락 파악은 기본적인 단계별 추론이 여전히 강력함. |

<div class="callout">
<span class="callout-title">추론 기법 상세 설명</span>

- **PoT (Program-of-Thoughts):** <br>수학 계산이나 논리 연산을 LLM이 직접 텍스트로 추론하지 않고, Python 코드와 같은 프로그래밍 언어를 생성하여 실행한 뒤 그 결과값을 답으로 채택하는 방식. 계산 실수가 획기적으로 줄어든다.
- **Analogical Reasoning:** <br>관련된 예제를 프롬프트에 제공하는 퓨샷(Few-shot)과 달리, 모델에게 "이 문제와 관련된 예시와 해설을 먼저 스스로 만들어봐"라고 시킨 뒤, 그 예시를 참고하여 본 문제를 풀게 하는 방식.
- **CoC (Chain-of-Code):** <br>딩 문제가 아니더라도 문제 해결 과정을 '의사 코드(Pseudo-code)'나 프로그래밍 로직처럼 작성하게 하여 논리적 구조를 강화하는 기법.
- **DecomP (Decomposed Prompting):** <br>복잡한 질문을 한 번에 풀지 않고, 여러 개의 쉬운 하위 질문(Sub-question)으로 분해(Decomposition)하여 순차적으로 해결하는 방식.
- **Active-Prompt:** <br>모델이 답변하기 가장 불확실해하는(Uncertainty가 높은) 질문들을 선별하고, 그 질문들에 대해서만 사람이 직접 주석(Annotation)이나 힌트를 달아주어 효율을 극대화하는 방식.
- **LoT (Library-of-Thought):** <br>다양한 유형의 사고 패턴이나 추론 방식을 '라이브러리'처럼 저장해두고, 질문의 유형에 맞춰 적절한 사고 방식을 꺼내어 적용하는 기법.
- **CoT (Chain-of-Thought):** <br>"단계별로 생각해봐(Let's think step by step)"와 같이, 중간 추론 과정을 명시적으로 생성하게 하여 답변의 정확도를 높이는 가장 대중적인 기법.
</div>

---

### ② 지식 및 질의응답(QA) 태스크
방대한 데이터에서 정보를 찾거나 복잡한 표(Table) 데이터를 해석하는 분야다.

| 태스크 (Task) | 추천 기법 (SoTA) | 특징 및 이유 |
| :--- | :--- | :--- |
| **표 기반 추론/QA** | **Chain-of-Table** / **Dater** | • **Chain-of-Table**: 표의 열/행을 조작하며 정답 접근.<br>• **Dater**: 표 데이터를 논리와 코드로 변환해 검증. |
| **다단계 추론 QA** | **DecomP** / **Active-Prompt** | 여러 문서를 건너뛰며 답을 찾을 때, 질문을 분해하거나 <br>불확실성을 줄이는 전략이 유효함. |
| **문맥 기반 QA** | **Implicit RAG** | 외부 지식을 명시적 덩어리가 아닌 문맥 속에 자연스럽게 녹여냄. |

<div class="callout">
<span class="callout-title">지식/QA 기법 상세 설명</span>

- **Chain-of-Table:** <br>텍스트가 아닌 표 데이터를 이해하기 위해, 필요한 열을 추가하거나 불필요한 행을 필터링하는 등 '표를 조작하는 단계'를 거치며 정답에 접근하는 방식.
- **Dater:** <br>거대한 표 데이터를 작은 단위로 분해(Decompose)하고, 이를 다시 쿼리나 코드로 변환하여 사실 여부(Truthfulness)를 검증하거나 답변을 찾아내는 기법.
- **Implicit RAG:** <br>검색된 지식(Context)을 "여기에 참고 자료가 있다"라고 명시적으로 덩어리째 주는 대신, 프롬프트나 대화 흐름 속에 자연스럽게 녹여내어 모델이 문맥을 더 유연하게 받아들이게 하는 검색 증강 생성 방식.
</div>

---

### ③ 텍스트 처리 및 분석 (NLP Core)
요약, 감정 분석 등 전통적인 NLP 영역에서도 특화된 프롬프트가 존재한다.

| 태스크 (Task) | 추천 기법 (SoTA) | 특징 및 이유 |
| :--- | :--- | :--- |
| **요약** | **CoE** | 사건의 시간 순서와 중요도를 연결(Event Chain)한 뒤 요약. |
| **감정 분야** | **THOR** | 인지 과정(측면 식별 → 의견 분석 → 감정 추론)을 3단계로 모방. |
| **개체명(NER)** | **MP** / **Annotation-Based** | • **MP**: 모델이 자신의 답을 스스로 모니터링하고 평가.<br>• **Annotation**: 에러 분석 기반의 가이드라인 제공. |

<div class="callout">
<span class="callout-title">텍스트 처리 기법 상세 설명</span>

- **CoE (Chain-of-Event):** <br>텍스트를 무작정 요약하는 대신, 글에 등장하는 주요 사건(Event)들을 시간 순서나 인과 관계에 따라 먼저 나열(Chain)하게 한 뒤, 이를 바탕으로 요약문을 작성하게 하는 방식.
- **THOR (Three-Hop Reasoning):** <br>인간의 감정 인식 과정을 모방하여 3단계로 추론하는 기법. 1단계에서 대상(Aspect)을 찾고, 2단계에서 의견(Opinion)을 분석하고, 3단계에서 최종 감정(Sentiment)을 도출한다.
- **MP (Metacognitive Prompting):** <br>인간의 메타인지(생각에 대한 생각)를 모방하여, 모델이 답변을 생성하는 과정에서 "이 이해가 맞는가?", "근거가 충분한가?"를 스스로 평가(Monitor & Evaluate)하게 만드는 기법.
- **Annotation-Based Prompting:** <br>특정 도메인(예: 의료)의 용어 정의나 기존 모델이 자주 틀리는 에러 유형에 대한 분석(Annotation)을 프롬프트에 미리 포함시켜 정답률을 높이는 방식.
</div>

---

### ④ 신뢰성 및 범용 심화 기법
모델의 환각을 줄이고 최종 답변의 품질을 극대화하는 기법이다.

| 목표 | 추천 기법 (SoTA) | 핵심 메커니즘 |
| :--- | :--- | :--- |
| **환각 방지/검증** | **CoVe** | 답변 후 스스로 검증 질문을 던져 교차 체크. |
| **복합 문제 해결** | **ER** | 여러 답변을 생성한 뒤 비평 과정을 거쳐 하나로 정제. |

<div class="callout">
<span class="callout-title">신뢰성 향상 기법 상세 설명</span>

- **CoVe (Chain-of-Verification):** <br>모델이 1차 답변을 생성한 후, 그 답변에 오류가 없는지 확인하기 위한 검증 질문들을 스스로 생성하고, 다시 그에 대해 답변하며 최종적으로 수정된 답을 내놓는 '자기 검증' 프로세스.
- **ER (Ensemble Refinement):** <br>하나의 프롬프트로 한 번만 답을 생성하는 것이 아니라, 여러 번 다양한 답변을 생성(Ensemble)하게 한 뒤, 이 답변들을 종합하고 비평하여 하나의 완성된 최적의 답변으로 정제(Refinement)하는 방식.
</div>

---

## 3. 마치며: 2026년의 시선에서

이 논문이 발표된 것은 2024년 7월, 지금으로부터 약 1년 반 전이다. 그사이 생성형 AI 모델은 더욱 빠른 속도로 발전해왔다.

개인적으로 LLM 성능이 고도화될수록 고전적인 의미의 프롬프트 엔지니어링은 큰 의미가 없어진다고 생각한다. 예를 들어, 최신 LLM 모델들은 사용자가 굳이 "단계별로 생각해(CoT)"라고 지시하지 않아도 내부적으로 추론 과정을 거쳐 답변을 생성하고, 필요하면 알아서 도구를 사용하기 시작한 지도 꽤 오래되었다.

하지만 **이 논문의 가치가 완전히 사라진 것은 아니다.**

만약 **로컬 환경에서 온디바이스 AI를 위해 SLM(Small Language Model)을 돌리는 상황**이라면 이야기는 달라진다. 경량화된 모델은 여전히 추론 능력이 부족하기 때문에, 위 논문에서 소개된 **PoT, DecomP, CoVe**와 같은 구조적인 프롬프팅 기법들이 모델의 성능을 한계까지 끌어올리는 데 매우 유용하게 사용될 수 있다.

또한, 이 기법들은 단순한 프롬프트가 아니라 **AI 에이전트(Agent)가 문제를 해결하는 논리적 설계도(Workflow)** 로서 여전히 유효하다.