[Pandas] 헷갈리는 데이터 정렬과 병합 완벽 정리 (sort, nlargest, merge)
데이터 분석 프로젝트를 시작할 때 가장 먼저 마주하는 벽은 '데이터 가져오기'와 '전처리'다. 이번에는 캐글(Kaggle) API를 통해 LinkedIn 데이터셋을 가져와 분석하기 좋은 형태로 가공하는 과정을 정리해 보았다.

단순히 데이터를 합치는 것을 넘어, "NaN 값을 어디에 둘 것인가?", "동점자는 어떻게 처리할 것인가?", "데이터의 관계(1:1, 1:M)는 올바른가?" 등 디테일한 옵션들을 파고들었을 때 비로소 데이터가 제대로 보이기 시작했다.

1. 정렬의 디테일: sort_values와 sort_index
데이터를 순서대로 나열하는 것은 기본 중의 기본이다. 하지만 결측치(NaN)가 포함되어 있다면 이야기가 달라진다.

값으로 정렬하기: na_position
보통 sort_values를 쓸 때 ascending=False(내림차순)만 신경 쓰곤 한다. 하지만 실무 데이터에는 결측치가 많다. 내림차순 정렬 시 NaN이 맨 위에 오면 데이터 확인이 불편할 때가 있는데, 이때 na_position 옵션이 유용하다.

Python

import pandas as pd
import numpy as np

# 실습을 위한 간단한 데이터 생성
data = {
    'companyName': ['Google', 'Apple', 'Samsung', 'Amazon', 'Meta'],
    'companyFollowerCount': [7502740, np.nan, 4385293, np.nan, 10047]
}
df = pd.DataFrame(data)

# 일반적인 내림차순 정렬 (NaN이 맨 뒤로 감)
print(df.sort_values(by='companyFollowerCount', ascending=False))

# NaN을 명시적으로 맨 앞으로 가져오기 (결측치 우선 확인 시 유용)
print(df.sort_values(by='companyFollowerCount', ascending=False, na_position='first'))
인덱스로 정렬하기: MultiIndex 제어
데이터를 그룹화하다 보면 인덱스가 여러 층(MultiIndex)으로 쌓일 때가 있다. 이때는 level 파라미터를 통해 층별로 정렬 순서를 다르게 줄 수 있다는 점을 새로 알게 되었다.

Python

# MultiIndex 정렬 예시
# 레벨 1은 내림차순(False), 레벨 0은 오름차순(True)으로 복합 정렬
df2.sort_index(axis=0, level=[1, 0], ascending=[False, True])
2. 상위 데이터 추출: head() 말고 nlargest()
보통 상위 5개를 볼 때 head(5)를 쓰지만, 특정 컬럼 기준 상위 n개를 뽑을 때는 nlargest()가 훨씬 직관적이다. 특히 '동점자 처리' 방식이 강력하다.

이번 실습에서 ageEstimate가 같은 데이터가 많았는데, keep 옵션에 따라 결과가 완전히 달라지는 것을 확인했다.

keep='first': 동점자 중 위에서부터 순서대로 자른다. (기본값)

keep='last': 동점자 중 아래에서부터 자른다.

keep='all': 동점자가 있으면 n개가 넘더라도 모두 포함해서 보여준다.

Python

# 나이 추정치(ageEstimate) 기준 상위 3개 추출
# 동점자가 있어도 3등과 값이 같다면 모두 출력함
top_ages = df.nlargest(n=3, columns='ageEstimate', keep='all')
print(top_ages[['ageEstimate', 'companyName']])
3. 데이터 병합의 세계: combine, join, merge
Pandas에는 데이터를 합치는 메서드가 정말 많다. 이번 기회에 각각의 용도를 명확히 구분해 보았다.

combine: 두 데이터프레임의 값을 '비교'해서 합칠 때 쓴다. (예: np.maximum으로 더 큰 값만 취하기)

join: 인덱스(Index) 기준으로 합칠 때 가장 간편하다. SQL의 Join과 비슷하지만 기준이 인덱스라는 점이 다르다.

merge: 가장 범용적이고 강력하다. 특정 **컬럼(Column)**을 기준으로 합칠 때 사용한다.

MergeError와 validate 파라미터의 중요성
실습 중 merge를 하다가 에러가 발생했다. 두 데이터프레임을 합칠 때 데이터의 관계(1:1, 1:M 등)를 명확히 하지 않으면 데이터가 뻥튀기되거나 로직이 꼬일 수 있다.

validate 파라미터를 쓰면 병합 전에 데이터 무결성을 검증해 준다.

Python

df7 = pd.DataFrame({'IDX': ['a', 'b', 'c', 'a'], 'VAL': [1, 2, 3, 4]}) # 'a'가 중복됨 (Keys are not unique)
df8 = pd.DataFrame({'IDX': ['a', 'c', 'd'], 'VAL': [5, 6, 7]})

# 시도: 1:M 관계라고 가정하고 검증을 시도함
try:
    # df7(Left)의 키가 유니크하지 않으므로 '1:m' 검증 실패 -> 에러 발생
    merged = df7.merge(df8, on='IDX', validate='1:m')
except Exception as e:
    print(f"Merge Error 발생: {e}")
    # 출력: Merge keys are not unique in left dataset; not a one-to-many merge

# 해결: 실제 데이터 관계에 맞는 'm:1' (Many-to-One)으로 검증
success = df7.merge(df8, on='IDX', validate='m:1')
print("병합 성공:\n", success)
새로 습득한 점:
validate 옵션은 필수는 아니지만, 실무에서 수백만 건의 데이터를 다룰 때 의도치 않은 'Cartesian Product(교차곱)'가 발생해 메모리가 터지는 것을 막아주는 안전벨트 역할을 한다.

4. 결론
Pandas는 단순히 데이터를 불러오고 자르는 도구가 아니라, 데이터의 구조를 이해하고 논리적으로 조작하는 도구다.

정렬할 때는 na_position으로 결측치를 전략적으로 배치하자.

순위가 중요하다면 nlargest의 keep 옵션을 활용하자.

merge를 할 때는 습관적으로 validate를 사용하여 데이터의 관계(1:1, 1:N)를 스스로 점검하자.

이 작은 디테일들이 모여 데이터 분석의 신뢰도를 높여준다.